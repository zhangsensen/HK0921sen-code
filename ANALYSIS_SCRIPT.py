#!/usr/bin/env python3
"""
ä»“åº“åˆ†æè„šæœ¬ - ç”¨äºè¯†åˆ«é‡å¤ä»£ç å’Œæ¸…ç†æœºä¼š
åœ¨æ‰§è¡Œæ¸…ç†å‰è¿è¡Œæ­¤è„šæœ¬æ¥äº†è§£å½“å‰çŠ¶æ€
"""

import ast
import json
import sys
from pathlib import Path
from typing import Dict, List

def find_python_files(root_dir: str) -> List[Path]:
    """æ‰¾åˆ°æ‰€æœ‰çš„Pythonæ–‡ä»¶"""
    root = Path(root_dir)
    return list(root.rglob("*.py"))

def analyze_file_structure(file_path: Path) -> Dict:
    """åˆ†ææ–‡ä»¶ç»“æ„å’Œå¯¼å…¥"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        tree = ast.parse(content)

        imports = []
        classes = []
        functions = []

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)
            elif isinstance(node, ast.ClassDef):
                classes.append(node.name)
            elif isinstance(node, ast.FunctionDef):
                functions.append(node.name)

        return {
            'path': str(file_path),
            'imports': imports,
            'classes': classes,
            'functions': functions,
            'lines': len(content.splitlines()),
        }
    except Exception as e:
        return {'path': str(file_path), 'error': str(e)}

def find_duplicate_files(root_dir: str) -> Dict[str, List[Path]]:
    """æ‰¾åˆ°å¯èƒ½çš„é‡å¤æ–‡ä»¶"""
    files = find_python_files(root_dir)
    name_groups = {}

    for file_path in files:
        name = file_path.name
        if name not in name_groups:
            name_groups[name] = []
        name_groups[name].append(file_path)

    return {name: paths for name, paths in name_groups.items() if len(paths) > 1}

def generate_report(root_dir: str) -> Dict:
    """ç”Ÿæˆå®Œæ•´çš„åˆ†ææŠ¥å‘Š"""
    print(f"ğŸ” åˆ†æä»“åº“: {root_dir}")

    # æ‰¾åˆ°é‡å¤æ–‡ä»¶
    duplicates = find_duplicate_files(root_dir)
    print(f"ğŸ“Š å‘ç° {len(duplicates)} ç»„é‡å¤æ–‡ä»¶å")

    # åˆ†ææ‰€æœ‰Pythonæ–‡ä»¶
    files = find_python_files(root_dir)
    analyses = []
    for file_path in files:
        analysis = analyze_file_structure(file_path)
        analyses.append(analysis)

    report = {
        'summary': {
            'total_files': len(files),
            'duplicate_groups': len(duplicates),
            'avg_lines': round(sum(item.get('lines', 0) for item in analyses) / max(len(analyses), 1), 2),
        },
        'duplicates': duplicates,
        'file_analyses': analyses
    }

    return report

def print_summary(report: Dict):
    """æ‰“å°åˆ†ææ‘˜è¦"""
    print("\n" + "="*60)
    print("ğŸ“‹ ä»“åº“åˆ†ææ‘˜è¦")
    print("="*60)

    summary = report['summary']
    print(f"æ€»Pythonæ–‡ä»¶æ•°: {summary['total_files']}")
    print(f"é‡å¤æ–‡ä»¶ç»„æ•°: {summary['duplicate_groups']}")
    print(f"å¹³å‡ä»£ç è¡Œæ•°: {summary['avg_lines']}")

    print("\nğŸ” é‡å¤æ–‡ä»¶è¯¦æƒ…:")
    for name, paths in report['duplicates'].items():
        print(f"  {name}:")
        for path in paths:
            print(f"    - {path}")

if __name__ == "__main__":
    root_dir = "."
    summary_only = False
    for arg in sys.argv[1:]:
        if arg == "--summary":
            summary_only = True
        else:
            root_dir = arg

    report = generate_report(root_dir)
    print_summary(report)

    if not summary_only:
        with open('cleanup_analysis.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: cleanup_analysis.json")
